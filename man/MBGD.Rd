% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StatComp21088R.R
\name{MBGD}
\alias{MBGD}
\title{Mini-Batch Gradient Descent}
\usage{
MBGD(input_data, real_result, batch_size, alpha, theta)
}
\arguments{
\item{input_data}{Input_data  matrix after adding constant 1 column}

\item{real_result}{Real_result vector whose length is equal to the column number of data.}

\item{batch_size}{Batch_size parameter constant}

\item{alpha}{Learning rate}

\item{theta}{The initial parameters of linear regression}
}
\value{
theta after iterations \code{theta}
}
\description{
It is a compromise between batch gradient descent and stochastic gradient descent.The idea is to use batch_size samples per iteration to update the parameters.
}
\examples{
\dontrun{
x <- seq(0.1,10,0.002)
n <- length(x)
y <- 2*x+5+rnorm(n)
z <- as.matrix(data.frame(rep(1,n),x))
theta <- MBGD(z, y, 100,0.002,c(1,1))
print(theta)
}
}
